{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XfuqZB9nico"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpHR8VMZodUy",
        "outputId": "d6a51ff2-6d6e-46f1-e6b7-872694ca412b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample dataset (replace with real dataset)\n",
        "data = [\n",
        "    (\"The cat sat on the mat\", 0),\n",
        "    (\"Dogs are loyal animals\", 1),\n",
        "    (\"Transformers are powerful models\", 1),\n",
        "    (\"Pytorch makes deep learning easy\", 0),\n",
        "]\n",
        "vocab = list(set(word for sentence, _ in data for word in sentence.split()))\n",
        "word2idx = {word: idx for idx, word in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "fHjHDIKVodLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dataset into token indices\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, data, word2idx, max_len=None):  # Add max_len parameter\n",
        "        self.data = [(torch.tensor([word2idx[word] for word in sentence.split()], dtype=torch.long), label)\n",
        "                     for sentence, label in data]\n",
        "        self.max_len = max_len if max_len else max(len(x[0]) for x in self.data)  # Calculate or use provided max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Pad sequences to max_len\n",
        "        tensor, label = self.data[idx]\n",
        "        padded_tensor = torch.zeros(self.max_len, dtype=torch.long)\n",
        "        padded_tensor[:len(tensor)] = tensor\n",
        "        return padded_tensor, label  # Return padded tensor\n",
        "\n",
        "dataset = TextDataset(data, word2idx)\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "tZ3xfsf9odIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer Model Definition\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, num_layers, hidden_dim, num_classes):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=hidden_dim)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)  # Shape: (batch_size, seq_len, embed_dim)\n",
        "        x = x.permute(1, 0, 2)  # Required shape for Transformer (seq_len, batch_size, embed_dim)\n",
        "        x = self.transformer_encoder(x)  # Apply transformer\n",
        "        x = x.mean(dim=0)  # Global Average Pooling\n",
        "        x = self.fc(x)  # Fully connected layer\n",
        "        return x"
      ],
      "metadata": {
        "id": "hl2FySeBodFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "vocab_size = len(vocab)\n",
        "embed_dim = 32\n",
        "num_heads = 2\n",
        "num_layers = 2\n",
        "hidden_dim = 64\n",
        "num_classes = 2"
      ],
      "metadata": {
        "id": "EYjMQbS-odCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model, Loss, Optimizer\n",
        "model = TransformerModel(vocab_size, embed_dim, num_heads, num_layers, hidden_dim, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdslNjbUoc_V",
        "outputId": "9939c11b-3fb4-47cd-a1ca-cded46ee76a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCBnFFFYya_w",
        "outputId": "d14641b9-3fc8-484d-ac91-70a8aa4d3041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerModel(\n",
            "  (embedding): Embedding(18, 32)\n",
            "  (encoder_layer): TransformerEncoderLayer(\n",
            "    (self_attn): MultiheadAttention(\n",
            "      (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
            "    )\n",
            "    (linear1): Linear(in_features=32, out_features=64, bias=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (linear2): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "    (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout1): Dropout(p=0.1, inplace=False)\n",
            "    (dropout2): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (transformer_encoder): TransformerEncoder(\n",
            "    (layers): ModuleList(\n",
            "      (0-1): 2 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=32, out_features=64, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=64, out_features=32, bias=True)\n",
            "        (norm1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=32, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "def train_model(model, dataloader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "train_model(model, dataloader, criterion, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehZfn03ooc7v",
        "outputId": "cef4da36-e5f4-4790-cb73-7bd15b28619c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.5348\n",
            "Epoch 2/10, Loss: 1.3328\n",
            "Epoch 3/10, Loss: 1.1457\n",
            "Epoch 4/10, Loss: 0.9914\n",
            "Epoch 5/10, Loss: 0.8922\n",
            "Epoch 6/10, Loss: 0.7466\n",
            "Epoch 7/10, Loss: 0.6351\n",
            "Epoch 8/10, Loss: 0.5214\n",
            "Epoch 9/10, Loss: 0.4268\n",
            "Epoch 10/10, Loss: 0.3852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Model\n",
        "torch.save(model.state_dict(), \"transformer_model.pth\")\n",
        "print(\"Model saved successfully!\")"
      ],
      "metadata": {
        "id": "T3REEYYxpDse",
        "outputId": "387cb610-6310-45d1-a4aa-c8e17e01ca75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ]
    }
  ]
}